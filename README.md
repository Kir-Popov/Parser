## Парсер магазина приложений Google Play. 
# Задание
Осуществить поиск приложений в Google Play по КЛЮЧЕВОМУ СЛОВУ.
Для каждого найденного приложения должна быть возвращена следующая информация:
1) название
2) url страницы приложения
3) автор
4) категория
5) описание
6) средняя оценка
7) количество оценок
8) последнее обновление
Сохранить приложения, в информации которых содерижится КЛЮЧЕВОЕ СЛОВО.
# Логика программы
В play market поиск приложений по названию выдает рекомендованные для данного запроса приложения в количестве 50 штук.
Но рекомендованных приложений может быть (на самом деле всегда) больше 50. Они прогружаюся динамически, по мере прокрутки 
сайта. Поэтому обычный get запрос здесь не подойдет. Попытался в браузере во вкладке networking отследить запросы, которые
появляются по мере прокрутки сайта. Закономерности найти не смог. Решено было использовать библиотеку selenium для имитации работы 
браузера. Во время работы программы открывается браузер со  страницей рекомендованных приложений, автоматически скролит 
ее до конца. После этого я могу скачать полную html страницу со всеми приложениями. Дальше по тегам нахожу ссылки на все 
приложения. Делаю get запросы по этим ссылкам и по нужным тегам цепляю информацию. Для работы с html использую библиотеку BeautifulSoup.
# Формат входных и выходных данных
На вход поступает строка - название бренда, по которому осуществляется поиск. На выходе json файл с названием apps.json в папке проекта.
# Инструкция по компиляции
pip3 install -r requirements.txt
sudo apt-get install chromium-chromedriver (Необходимо установить драйвер браузера, который должен лежать /usr/lib/chromium-browser/chromedriver. Если компиляция на Windows, то в 12 строке файла main.py надо правильно указать путь к драйверу. Да это плохо, но спрашивать у пользователя каждый раз путь к драйверу еще хуже)
