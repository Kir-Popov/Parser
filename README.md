# Парсер магазина приложений Google Play. 
## Задание
Осуществить поиск приложений в Google Play по КЛЮЧЕВОМУ СЛОВУ.
Для каждого найденного приложения должна быть возвращена следующая информация:
- название
- url страницы приложения
- автор
- категория
- описание
- средняя оценка
- количество оценок
- последнее обновление
- 
Сохранить приложения, в информации которых содержится КЛЮЧЕВОЕ СЛОВО.

В рамках доп задания нужно реализовать параллельную обработку.
## Логика программы
В play market поиск приложений по названию выдает рекомендованные для данного запроса приложения в количестве 50 штук. Но рекомендованных приложений может быть (на самом деле всегда) больше 50. Они прогружаются динамически, по мере прокрутки сайта. Поэтому обычный get запрос здесь не подойдет.

Попытался в браузере во вкладке networking отследить запросы, которые появляются по мере прокрутки сайта. Это post запросы с невалидном json текстом. Видимо он передается напрямую в js скрипт, поэтому нужно использовать браузерный движок для имитации работы браузера. Решено было использовать библиотеку selenium. 

Во время работы программы открывается браузер со страницей рекомендованных приложений, автоматически скролит ее до конца. После этого я могу скачать полную html страницу со всеми приложениями. Дальше по тегам нахожу ссылки на все приложения. Делаю асинхронные get запросы по этим ссылкам (с помощью библиотеки aiohttp) и по нужным тегам цепляю информацию. Для работы с html использую библиотеку BeautifulSoup.
## Формат входных и выходных данных
На вход поступает строка - название бренда, по которому осуществляется поиск. На выходе json файл с названием apps.json в папке проекта.
## Инструкция по компиляции
1) pip3 install -r requirements.txt 
2) sudo apt-get install chromium-chromedriver 
###
!!! Необходимо установить драйвер хромиум браузера и вписать путь к драйверу в файл config.py !!!
